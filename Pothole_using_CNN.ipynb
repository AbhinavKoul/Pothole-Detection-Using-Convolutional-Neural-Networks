{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pothole using CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhinavKoul/Pothole-Detection-Using-Convolutional-Neural-Networks/blob/Backend/Pothole_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3b4OV10z3mK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKB36YLvz8-m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "d3c29a52-730c-4859-a55d-34fa1ee131a4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk8_-ezr0xvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a57c3515-f3a4-4a93-9a25-6161c0f68d12"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Potholes Dataset\")\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Dataset 1 (Simplex)'   README.txt\t     'Subset 2 (Complex)'\n",
            "'Dataset 2 (Complex)'  'Subset 1 (Simplex)'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI3LPTux1DH9",
        "colab_type": "text"
      },
      "source": [
        "REACHED REQUIRED DIRECTORY."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_JKbfqx0zSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import os\n",
        "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#    for filename in filenames:\n",
        "#        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import cv2\n",
        "import math\n",
        "import random #rng\n",
        "from PIL import Image #handle images\n",
        "import matplotlib.pyplot as plt #plot data\n",
        "from matplotlib.patches import Polygon #draw polygons on plots\n",
        "import re #regex\n",
        "from subprocess import check_output #run commands\n",
        "%tensorflow_version 1.x\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dropout, Flatten, Conv2D, Convolution2D, MaxPooling2D, Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBdGZvfX15Ah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04c7588d-aff2-42a8-e379-967f848b2122"
      },
      "source": [
        "class ImageData:\n",
        "    def __init__(self, img_name, boxes):\n",
        "        self.img_name = img_name\n",
        "        self.boxes = boxes\n",
        "\n",
        "def parse_directory(path):\n",
        "    \"\"\"Parse a directory containing negative images to a list of ImageData\"\"\"\n",
        "    img_names = check_output([\"ls\", path]).decode(\"utf8\").split(\"\\n\")\n",
        "    data = []\n",
        "    for img_name in img_names:\n",
        "        match = re.search(r'G\\d+\\.JPG', img_name)\n",
        "        if(match):\n",
        "            data.append(ImageData(match.group(), []))\n",
        "    return data\n",
        "    \n",
        "def parse_txt_file(filepath, filename):\n",
        "    \"\"\"Parse the txt file containing image relative paths, name, and boxes data to a list of ImageData\"\"\"\n",
        "    file = open(filepath + filename)\n",
        "    items = file.read().strip().split(\"\\n\")\n",
        "    item_regex = r'(^[\\w\\s]+\\\\(?:[\\w\\s]+\\\\)*G\\d+\\.bmp)\\s+(\\d+)\\s+((?:\\d+\\s+\\d+\\s+\\d+\\s+\\d+\\s*)+)'\n",
        "    \n",
        "    def parse_item(item):\n",
        "        match = re.match(item_regex, item)\n",
        "        \n",
        "        img_path = match.group(1).replace('.bmp', '.JPG') #txt says bmp but images are actually jpg\n",
        "        img_name = re.search(r'G\\d+\\.JPG', img_path).group()\n",
        "        num_boxes = int(match.group(2))\n",
        "        values = re.findall(r'\\d+', match.group(3))\n",
        "        boxes = [tuple([ int(values[i*4+j]) for j in range(0,4)]) for i in range(0,num_boxes)]\n",
        "        \n",
        "        return ImageData(img_name, boxes)\n",
        "    \n",
        "    return [parse_item(item) for item in items]\n",
        "\n",
        "\n",
        "class ImageColleciton:\n",
        "    def __init__(self, data, path):\n",
        "        self.data = data\n",
        "        self.path = path\n",
        "        \n",
        "src_path = \"/content/drive/My Drive/Potholes Dataset/\"    # file location\n",
        "dataset2_path = src_path + \"Dataset 2 (Complex)/\"\n",
        "dataset1_path = src_path + \"Dataset 1 (Simplex)/\"\n",
        "\n",
        "img_collections = {\n",
        "    \"dataset2_complex\": {\n",
        "    #     \"train\": {\n",
        "    #         \"positive\": ImageColleciton(\n",
        "    #             parse_txt_file(dataset2_path, \"complexTrainFullSizeAllPotholes.txt\"),\n",
        "    #             dataset2_path + \"Train data/Positive data/\"\n",
        "    #         ),\n",
        "    #         \"negative\": ImageColleciton(\n",
        "    #             parse_directory(dataset2_path + \"Train data/Negative data/\"),\n",
        "    #             dataset2_path + \"Train data/Negative data/\"\n",
        "    #         )\n",
        "    #     },\n",
        "        \"test\": ImageColleciton( #test images have only positive data\n",
        "            parse_txt_file(dataset2_path, \"complexTestFullSizeAllPotholes.txt\"),\n",
        "            dataset2_path + \"Test data/\"\n",
        "        ),\n",
        "    },\n",
        "    \"dataset1_simplex\": {\n",
        "        # \"train\": {\n",
        "        #     \"positive\": ImageColleciton(\n",
        "        #         parse_txt_file(dataset1_path, \"simpleTrainFullPhotosSortedFullAnnotations.txt\"),\n",
        "        #         dataset1_path + \"Train data/Positive data/\"\n",
        "        #     ),\n",
        "        #     \"negative\": ImageColleciton(\n",
        "        #         parse_directory(dataset1_path + \"Train data/Negative data/\"),\n",
        "        #         dataset1_path + \"Train data/Negative data/\"\n",
        "        #     )\n",
        "        # },\n",
        "        \"test\": ImageColleciton( #test images have only positive data\n",
        "            parse_txt_file(dataset1_path, \"simpleTestFullSizeAllPotholesSortedFullAnnotation.txt\"),\n",
        "            dataset1_path + \"Test data/\"\n",
        "        ),\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"done \" + str(random.random()))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done 0.1497424855963193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMej4EYk3dw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}